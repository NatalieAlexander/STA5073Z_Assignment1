"0","#prepare dataframe for all BEST model results"
"0","all_results = data.frame(model_ID = character(), parameters= character(),"
"0","           train_accuracy = double(), valid_accuracy = double(), test_accuracy = double(), "
"0","           train_f1 = double(), valid_f1 = double(), test_f1 =  double(), "
"0","           train_precision = double(), valid_precision = double(), test_precision  = double(), "
"0","           train_recall = double(), valid_recall = double(), test_recall = double())"
"0",""
"0","#create word bag"
"0","set.seed(123)"
"0","word_bag <- sona_tokenized_by_word %>%"
"0","  group_by(sentence_id, president_label, word) %>%"
"0","  count() %>% #frequency of word "
"0","  ungroup() %>%"
"0","  top_n(200, wt = n) %>% #select top 200 most frequent words"
"0","  select(-n) #remove frequency of words column"
"0",""
"0","#dimensions of word bag"
"0","nrow(word_bag)"
"1","[1]"
"1"," 363"
"1","
"
"0","ncol(word_bag)"
"1","[1]"
"1"," 3"
"1","
"
"0","#find the most frequently used words by each president"
"0","sona_tdf = sona_tokenized_by_word %>% inner_join(word_bag) %>%"
"0","  group_by(sentence_id,president_label, word) %>%"
"0","  count() %>% #frequency of most frequently used words "
"0","  group_by(president_label) %>%"
"0","  mutate(total = sum(n)) %>% #get per president_label frequency"
"0","  ungroup()"
"0",""
"0",""
"0","#create bag of words table"
"0","bag_of_words = sona_tdf %>%"
"0","  select(sentence_id, president_label, word, n) %>%"
"0","  group_by(sentence_id, president_label)%>%"
"0","  pivot_wider(names_from = word, values_from = n, values_fill = 0)"
"0",""
